{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import time\n",
    "import pyspark.sql.functions as F\n",
    "from utils import *\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StringType, ArrayType, IntegerType\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "CELL_AREA    = '/data/cell_area.csv'\n",
    "PARQUETS_DIR = '/data/parquets'\n",
    "CURRENT_DIR  = '/home/hellscream/Documents/backendSpark'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_start = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataFrame Schema"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "root\n",
    " |-- code: string (nullable = true)\n",
    " |-- towers: array (nullable = true)\n",
    " |    |-- element: string (containsNull = true)\n",
    " |-- times: array (nullable = true)\n",
    " |    |-- element: integer (containsNull = true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Spark Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SparkSessionBase():\n",
    "    def __init__(self):\n",
    "        self.spark = SparkSession\\\n",
    "                     .builder\\\n",
    "                     .appName('Mobility')\\\n",
    "                     .getOrCreate()\n",
    "        \n",
    "        self.cell_area_df = self.spark.read.format('csv').options(header='true', delimiter='\\t')\\\n",
    "                         .load(CURRENT_DIR + CELL_AREA)\\\n",
    "                         .select('id', 'area_correlator')\n",
    "        \n",
    "        cell_area_pandas = self.cell_area_df.toPandas()\n",
    "        cell_area_idx = cell_area_pandas.to_dict('index')\n",
    "        self.cell_area = {}\n",
    "        \n",
    "        for i in cell_area_idx:\n",
    "            x = cell_area_idx[i]['id']\n",
    "            y = cell_area_idx[i]['area_correlator']\n",
    "            if y != None:\n",
    "                self.cell_area[x] = y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mobility Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mobility(SparkSessionBase):\n",
    "    def __init__(self, date, time_start_lower, time_start_high, time_end_lower,\n",
    "        time_end_high, time_sleep_lower='01:00', time_sleep_high='04:00'):\n",
    "        super().__init__()\n",
    "        self.date = date\n",
    "        \n",
    "    def get_mobility_at_time_interval(self, time_start, time_end):\n",
    "        # load correspondent parquet\n",
    "        \n",
    "        time_start *= 3600\n",
    "        time_end *= 3600\n",
    "        \n",
    "        df = self.spark.read.parquet(CURRENT_DIR + PARQUETS_DIR + '/' + self.date)\n",
    "\n",
    "        get_range_udf = F.udf(lambda elems, a, b : get_range(elems, a, b), ArrayType(IntegerType()))\n",
    "\n",
    "        df = df.withColumn('range', get_range_udf(df.times, F.lit(time_start), F.lit(time_end)))\\\n",
    "               .select(df.code,\\\n",
    "               F.slice(df.cell_ids, F.col('range')[0], F.col('range')[1]).alias('towers'),\\\n",
    "               F.slice(df.times,  F.col('range')[0], F.col('range')[1]).alias('times'))\\\n",
    "               .where(F.size(F.col('towers')) > 0)\n",
    "        \n",
    "        mapp = self.cell_area\n",
    "        \n",
    "        df = df.rdd.flatMap(lambda x : mapp_tow_cell(x, mapp)).toDF(['code', 'towers', 'times'])\n",
    "        count_occurrences_udf = F.udf(lambda x : count_occurrences_and_normalize(x),\\\n",
    "                                      ArrayType(ArrayType(StringType())))\n",
    "        df = df.select('code', count_occurrences_udf(F.col('towers')).alias('towers-count'))\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def build(self, users_cells_start, users_cells_end):\n",
    "        union_user_cells = user_cells_start.union(user_cells_end)\n",
    "        \n",
    "        union_user_cells = union_user_cells.groupBy('code')\\\n",
    "                                           .agg(F.collect_list('towers-count').alias('cells'), F.count('code')\\\n",
    "                                                .alias('count'))\\\n",
    "                                           .filter(F.col('count') == 2)\n",
    "        \n",
    "        rdd = union_user_cells.select('cells').rdd.flatMap(lambda x : flat_origin_destination_product(x))\n",
    "        df = rdd.toDF(['start', 'end', 'value'])\n",
    "        df = df.groupBy('start').pivot('end').agg(F.sum('value'))\n",
    "        \n",
    "        matriz_pandas = df.toPandas()\n",
    "        matriz_pandas.to_json('/home/hellscream/Documents/mobility_spark/data/2021-03-01.json', 'index')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Mobility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "mobility_instance = Mobility('2021-03-01', None, None, None, None)\n",
    "\n",
    "user_cells_start = mobility_instance.get_mobility_at_time_interval(6, 10)\n",
    "user_cells_end   = mobility_instance.get_mobility_at_time_interval(16, 20)\n",
    "\n",
    "mobility_instance.build(user_cells_start, user_cells_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time elapsed:9.911337133248647\n"
     ]
    }
   ],
   "source": [
    "time_end = time.time()\n",
    "print('time elapsed:' + str((time_end - time_start) / 60))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User Mobility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UserMobility(SparkSessionBase):\n",
    "    def __init__(self, date):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.date = date\n",
    "        \n",
    "        '''\n",
    "        self.imsi_mobility = {}  # amount of km and cell_changes\n",
    "        self.users_cells_start = {}  # count tower night to set home\n",
    "        '''\n",
    "        \n",
    "    def get_users_mobility(self, start_time=25200, end_time=72000, sleep_time_start=3600, sleep_end_time=14400):\n",
    "        df = self.spark.read.parquet(CURRENT_DIR + PARQUETS_DIR + '/' + self.date)\n",
    "        df = df.rdd.flatMap(lambda rows : between_ab_OR_dc(rows, (start_time, end_time), (sleep_time_start, sleep_end_time))).toDF(['code', 'cell_ids', 'times'])\n",
    "        df = df.select('*').where(F.size(df.times) > 0)\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+--------------------+\n",
      "| code|            cell_ids|               times|\n",
      "+-----+--------------------+--------------------+\n",
      "| 1804|[176-1146, 176-11...|[6469, 7968, 8016...|\n",
      "| 3108|[73-1350, 475-460...|[33565, 58725, 58...|\n",
      "| 3905|[475-4593, 475-45...|[13447, 27849, 42...|\n",
      "| 5905|[76-11563, 107-82...|[30240, 30242, 30...|\n",
      "| 6616|[476-5363, 4731-1...|[41384, 41901, 42...|\n",
      "| 7216|[453-69, 453-69, ...|[10380, 39310, 46...|\n",
      "| 9413|[450-289, 450-289...|[8489, 12091, 264...|\n",
      "|10006| [821-251, 821-8541]|      [30451, 68885]|\n",
      "|11117|[338-96, 338-19, ...|[7223, 26725, 269...|\n",
      "|13219|[71-735, 71-735, ...|[10524, 32229, 57...|\n",
      "|14507|         [454-17061]|             [11175]|\n",
      "|17019|           [74-8262]|              [8324]|\n",
      "|20210|[74-10321, 76-108...|[32205, 39372, 40...|\n",
      "|20702|[173-1516, 173-80...|[34040, 34057, 34...|\n",
      "|21519|[322-130, 321-331...|[25787, 25818, 26...|\n",
      "|25918|[455-676, 455-59,...|[6466, 7792, 8051...|\n",
      "|26909| [76-1011, 76-10131]|      [67779, 68559]|\n",
      "|30516|[1450-639, 1452-2...|[25523, 25545, 27...|\n",
      "|31116|         [821-12892]|              [4557]|\n",
      "|33400|[76-20407, 76-204...|[30545, 30569, 30...|\n",
      "+-----+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "um = UserMobility('2021-03-01')\n",
    "set1 = um.get_users_mobility()\n",
    "set1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "TODO:\n",
    "1. map cell_ids\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

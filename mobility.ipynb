{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import time\n",
    "import numpy as np\n",
    "import pyspark.sql.functions as F\n",
    "from utils import *\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StringType, ArrayType, IntegerType\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "CELL_AREA    = '/data/cell_area.csv'\n",
    "PARQUETS_DIR = '/data/parquets'\n",
    "CURRENT_DIR  = '/home/hellscream/Documents/backendSpark'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_start = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataFrame Schema"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "root\n",
    " |-- code: string (nullable = true)\n",
    " |-- towers: array (nullable = true)\n",
    " |    |-- element: string (containsNull = true)\n",
    " |-- times: array (nullable = true)\n",
    " |    |-- element: integer (containsNull = true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Spark Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SparkSessionBase():\n",
    "    def __init__(self):\n",
    "        self.spark = SparkSession\\\n",
    "                     .builder\\\n",
    "                     .appName('Mobility')\\\n",
    "                     .getOrCreate()\n",
    "        \n",
    "        # Map cell_area.csv\n",
    "        self.dic_full_df = self.spark.read.format('csv').options(header='true', delimiter='\\t')\\\n",
    "                         .load(CURRENT_DIR + CELL_AREA)\\\n",
    "                         .select('*')\n",
    "                         \n",
    "        dic_full_pandas = self.dic_full_df.toPandas()\n",
    "        self.dic_full   = dic_full_pandas.to_dict('index')\n",
    "        \n",
    "        self.dic_tow_cell = {}\n",
    "        for i in self.dic_full:\n",
    "            self.dic_tow_cell[self.dic_full[i]['id']] = self.dic_full[i]['area_correlator'] \n",
    "        \n",
    "        self.dic_cell_latlon = {}\n",
    "        for i in self.dic_full:\n",
    "            self.dic_cell_latlon[self.dic_full[i]['area_correlator']] = [self.dic_full[i]['latitude'], self.dic_full[i]['longitude']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mobility Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mobility(SparkSessionBase):\n",
    "    def __init__(self, date, time_start_lower, time_start_high, time_end_lower,\n",
    "        time_end_high, time_sleep_lower='01:00', time_sleep_high='04:00'):\n",
    "        super().__init__()\n",
    "        self.date = date\n",
    "        \n",
    "    def get_mobility_at_time_interval(self, time_start, time_end):\n",
    "        # load correspondent parquet\n",
    "        \n",
    "        time_start *= 3600\n",
    "        time_end *= 3600\n",
    "        \n",
    "        df = self.spark.read.parquet(CURRENT_DIR + PARQUETS_DIR + '/' + self.date)\n",
    "\n",
    "        get_range_udf = F.udf(lambda elems, a, b : get_range(elems, a, b), ArrayType(IntegerType()))\n",
    "\n",
    "        df = df.withColumn('range', get_range_udf(df.times, F.lit(time_start), F.lit(time_end)))\\\n",
    "               .select(df.code,\\\n",
    "               F.slice(df.cell_ids, F.col('range')[0], F.col('range')[1]).alias('towers'),\\\n",
    "               F.slice(df.times,  F.col('range')[0], F.col('range')[1]).alias('times'))\\\n",
    "               .where(F.size(F.col('towers')) > 0)\n",
    "        \n",
    "        mapp = self.cell_area\n",
    "        df = df.rdd.flatMap(lambda x : mapp_tow_cell(x, mapp)).toDF(['code', 'towers', 'times'])\n",
    "        \n",
    "        count_occurrences_udf = F.udf(lambda x : count_occurrences_and_normalize(x),\\\n",
    "                                      ArrayType(ArrayType(StringType())))\n",
    "        \n",
    "        df = df.select('code', count_occurrences_udf(F.col('towers')).alias('towers-count'))\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def count_occurrences_and_normalize(elems):\n",
    "        d = {}\n",
    "        for i in elems:\n",
    "            if i not in d:\n",
    "                d[i] = 1\n",
    "            else:\n",
    "                d[i] += 1\n",
    "        normalize = float(np.sum(np.array([count for count in d.values()])))\n",
    "        for i in d:\n",
    "            d[i] /= normalize\n",
    "            d[i] = round(d[i], 4)\n",
    "        return list(map(list, d.items()))\n",
    "\n",
    "    def flat_origin_destination_product(row):\n",
    "        for cell_start, val_1 in row[0][0]:\n",
    "            for cell_end, val_2 in row[0][1]:\n",
    "                yield (cell_start, cell_end, float(val_1) * float(val_2))\n",
    "    \n",
    "    def build(self, users_cells_start, users_cells_end):\n",
    "        union_user_cells = user_cells_start.union(user_cells_end)\n",
    "        \n",
    "        union_user_cells = union_user_cells.groupBy('code')\\\n",
    "                                           .agg(F.collect_list('towers-count').alias('cells'), F.count('code')\\\n",
    "                                                .alias('count'))\\\n",
    "                                           .filter(F.col('count') == 2)\n",
    "        \n",
    "        rdd = union_user_cells.select('cells').rdd.flatMap(lambda x : flat_origin_destination_product(x))\n",
    "        df = rdd.toDF(['start', 'end', 'value'])\n",
    "        df = df.groupBy('start').pivot('end').agg(F.sum('value'))\n",
    "        \n",
    "        matriz_pandas = df.toPandas()\n",
    "        matriz_pandas.to_json('/home/hellscream/Documents/mobility_spark/data/2021-03-01.json', 'index')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Mobility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Mobility' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-2665664387cf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmobility_instance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMobility\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'2021-03-01'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0muser_cells_start\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmobility_instance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_mobility_at_time_interval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0muser_cells_end\u001b[0m   \u001b[0;34m=\u001b[0m \u001b[0mmobility_instance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_mobility_at_time_interval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Mobility' is not defined"
     ]
    }
   ],
   "source": [
    "mobility_instance = Mobility('2021-03-01', None, None, None, None)\n",
    "\n",
    "user_cells_start = mobility_instance.get_mobility_at_time_interval(6, 10)\n",
    "user_cells_end   = mobility_instance.get_mobility_at_time_interval(16, 20)\n",
    "\n",
    "mobility_instance.build(user_cells_start, user_cells_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time elapsed:0.09680790106455485\n"
     ]
    }
   ],
   "source": [
    "time_end = time.time()\n",
    "print('time elapsed:' + str((time_end - time_start) / 60))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User Mobility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UserMobility(SparkSessionBase):\n",
    "    def __init__(self, date):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.date = date\n",
    "        \n",
    "        '''\n",
    "        self.imsi_mobility = {}  # amount of km and cell_changes\n",
    "        self.users_cells_start = {}  # count tower night to set home\n",
    "        '''\n",
    "    \n",
    "    def km_displacement(elems):\n",
    "        res = []\n",
    "        for i in range(len(elems)-1):\n",
    "            d = distance_in_km_between_coordinates(elems[i], elems[i+1])\n",
    "            res.append(d)\n",
    "        return sum(res)\n",
    "    \n",
    "    def map_area_correlator_to_coord(towers, mapp):\n",
    "        res = []\n",
    "        for i in towers:\n",
    "            res.append(mapp[i])\n",
    "        return res\n",
    "    \n",
    "    def get_users_mobility(self, start_time=25200, end_time=72000, sleep_start_time=3600, sleep_end_time=14400):\n",
    "        df = self.spark.read.parquet(CURRENT_DIR + PARQUETS_DIR + '/' + self.date)\n",
    "        \n",
    "        df = df.rdd.flatMap(lambda rows : between_ab_OR_dc(rows, (start_time, end_time), (sleep_start_time, sleep_end_time))).toDF(['code', 'cell_ids', 'times'])\n",
    "        df = df.select('*').where(F.size(df.times) > 0)\n",
    "        \n",
    "        # imsi -> cell changes & amount of distinct cell\n",
    "        distinct_cells_df = df.withColumn('distinct_cells', F.array_distinct(F.col('cell_ids'))).select('code', 'distinct_cells', F.size(F.col('distinct_cells')).alias('amount'))\n",
    "        \n",
    "        mapp = self.dic_tow_cell\n",
    "        df = df.rdd.flatMap(lambda x : mapp_tow_cell(x, mapp)).toDF(['code', 'towers', 'times'])\n",
    "                \n",
    "        # imsi -> km displacement\n",
    "        mapp = self.dic_cell_latlon\n",
    "        km_displacement_df = df.rdd.flatMap(lambda x : mapp_cell_latlon(x, mapp)).toDF(['code', 'cells', 'lat_lon'])\n",
    "        km_displacement_udf = F.udf(lambda coordinates : amount_km(coordinates), StringType())\n",
    "        km_displacement_df = km_displacement_df.withColumn('km_displacement', km_displacement_udf(F.col('lat_lon'))).select('code', 'km_displacement')\n",
    "        \n",
    "        # imsi -> amount of distinct towers\n",
    "        distinct_towers_df = df.withColumn('distinct_towers', F.array_distinct(F.col('towers'))).select('code', 'distinct_towers', F.size(F.col('distinct_towers')).alias('amount')) \n",
    "        \n",
    "        # process for establish sleeping zone\n",
    "        users_cells_start = df.rdd.flatMap(lambda x : accumulate_count(x, sleep_start_time, sleep_end_time)).toDF(['code', 'towers', 'count'])\n",
    "        users_cells_start = users_cells_start.select('*').where(F.size('towers') > 0)\n",
    "        \n",
    "        map_area_correlator_to_coord_udf = F.udf(lambda x : map_area_correlator_to_coord(x, mapp))\n",
    "        users_cells_start = users_cells_start.withColumn('coords', map_area_correlator_to_coord_udf(F.col('towers'))).select('*')\n",
    "\n",
    "        normalize_udf = F.udf(lambda values : [val / sum(values) for val in values])\n",
    "        users_cells_start = users_cells_start.withColumn('weight', normalize_udf(F.col('count'))).select('code', 'towers', 'weight', 'coords')\n",
    "        \n",
    "        \n",
    "        #return (distinct_cells_df, distinct_towers_df)\n",
    "        #return km_displacement_df\n",
    "        #return distinct_towers_df\n",
    "        return users_cells_start   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+--------------------+--------------------+\n",
      "| code|              towers|              weight|              coords|\n",
      "+-----+--------------------+--------------------+--------------------+\n",
      "| 1804|            [dhj7jg]|               [1.0]|[[23.0459, -82.35...|\n",
      "| 3905|              [dhj6]|               [1.0]|[[22.9357, -82.54...|\n",
      "| 7216|             [dhn4h]|               [1.0]|[[22.8566, -81.34...|\n",
      "| 9413|             [dhn6b]|               [1.0]|[[23.0226, -81.19...|\n",
      "|11117|             [d5zup]|               [1.0]|[[21.8348, -78.76...|\n",
      "|13219|            [dhj7zc]|               [1.0]|[[23.0962, -82.16...|\n",
      "|14507|             [d5ymu]|               [1.0]|[[22.1443, -81.019]]|\n",
      "|17019|            [dhj7tk]|               [1.0]|[[23.1401, -82.38...|\n",
      "|25918|             [dhjgp]|               [1.0]|[[23.0465, -81.58...|\n",
      "|31116|              [d5ur]|               [1.0]|[[22.4173, -83.735]]|\n",
      "|35619|              [dhh2]|               [1.0]|[[22.6033, -83.80...|\n",
      "|36600|            [dhj7mz]|               [1.0]|[[23.1125, -82.35...|\n",
      "|38409|             [dhn18]|               [1.0]|[[22.7959, -81.53...|\n",
      "|39404|            [dhj7z0]|               [1.0]|[[23.1615, -82.30...|\n",
      "|41119|              [dhj6]|               [1.0]|[[22.9357, -82.54...|\n",
      "|41713|            [dhj6xj]|               [1.0]|[[22.9717, -82.305]]|\n",
      "|43211|            [dhj7t4]|               [1.0]|[[23.1289, -82.39...|\n",
      "|46216|[dhj7wq, dhj7w6, ...|[0.30769230769230...|[[23.1503, -82.33...|\n",
      "|46800|             [d79r2]|               [1.0]|[[20.968, -76.9688]]|\n",
      "|47101|            [dhj7ne]|               [1.0]|[[23.0445, -82.32...|\n",
      "+-----+--------------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "um = UserMobility('2021-03-01')\n",
    "set1 = um.get_users_mobility()\n",
    "set1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([20.4, 30.3])"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "mean = np.array([.4, .3])\n",
    "tmpp = np.array([10, 15])\n",
    "\n",
    "mean + tmpp * 2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(['dhj7jg', 'dhj7jg', 'dhj7jg', 'dhj7jg', 'dhj7jg', 'dhj7jg', 'dhj7jg', 'dhj7jg', 'dhj7jg', 'dhj7jg', 'dhj7jg', 'dhj7jg', 'dhj7jg', 'dhj7jg', 'dhj7jg', 'dhj7jg', 'dhj7jg', 'dhj7jg', 'dhj7jg', 'dhj7jg', 'dhj7jg', 'dhj7jg', 'dhj7jg', 'dhj7jg'], 24)\n"
     ]
    }
   ],
   "source": [
    "cells = set1.rdd.take(1)[0][1]\n",
    "print((cells, len(cells)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(['176-1146', '176-1146', '176-1146', '176-1146', '176-1146', '176-1146', '176-1146', '176-1146', '176-1146', '176-1146', '176-1146', '176-1146', '176-1146', '176-1146', '176-1146', '176-1146', '176-1146', '176-1146', '176-1146', '176-1146', '176-1146', '176-1146', '176-1146', '176-1146'], 24)\n"
     ]
    }
   ],
   "source": [
    "tows = set1.rdd.take(1)[0][1]\n",
    "print((tows, len(tows)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
